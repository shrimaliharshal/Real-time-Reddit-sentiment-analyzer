{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jch7lHcii3ll"
      },
      "source": [
        "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBrsDPrji3lr"
      },
      "source": [
        "# Spark NLP Quick Start\n",
        "### How to use Spark NLP pretrained pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTksH1MWi3ls"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/quick_start_google_colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce3yQj_Oi3lt"
      },
      "source": [
        "We will first set up the runtime environment and then load pretrained Entity Recognition model and Sentiment analysis model and give it a quick test. Feel free to test the models on your own sentences / datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQOObJLai3lv",
        "outputId": "f7ebb720-4abc-47c7-81ee-075ba2608a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-01 04:07:51--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2024-03-01 04:07:52--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-01 04:07:52 (50.5 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 5.3.0\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.8/564.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1QcfVTZi3ly",
        "outputId": "c29c9bf3-2412-4400-d182-51972f7ddcfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 5.3.0\n",
            "Apache Spark version: 3.2.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZTFA907i3lz"
      },
      "outputs": [],
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN9l4OZii3l3",
        "outputId": "6bb6612a-8be1-47e4-e34b-401670adad4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analyze_sentimentdl_glove_imdb download started this may take some time.\n",
            "Approx size to download 154.1 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "pipeline = PretrainedPipeline('analyze_sentimentdl_glove_imdb', 'en')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw"
      ],
      "metadata": {
        "id": "7unkil4sjrXc",
        "outputId": "2f8a30db-2587-434f-bd98-665b809b12eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.7.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.2.2)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "Kt8eSowZjnhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = 'comedy'"
      ],
      "metadata": {
        "id": "ojWTA6w4JeU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize PRAW with Reddit API credentials\n",
        "reddit = praw.Reddit(client_id='R2hyuU2V_wnLGBZyFEVLtw',\n",
        "                     client_secret='ayv3CTLaTdIot3qpXqqoGCrQq8KM3A',\n",
        "                     user_agent='web bot')\n",
        "\n",
        "subreddit = reddit.subreddit('shortstories')\n",
        "\n",
        "# Collect flairs/tags\n",
        "flair_counts = {}\n",
        "for post in subreddit.new(limit=100):\n",
        "    flair = post.link_flair_text\n",
        "    if flair:\n",
        "        flair_counts[flair] = flair_counts.get(flair, 0) + 1\n",
        "\n",
        "flair_df = pd.DataFrame(list(flair_counts.items()), columns=['Flair', 'Count'])\n",
        "print(flair_df.sort_values(by='Count', ascending=False))\n",
        "\n",
        "def scrape_posts_by_keyword(subreddit_name, keyword, limit=50):\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    posts_data = []\n",
        "\n",
        "    for post in subreddit.search(keyword, limit=limit):\n",
        "        post_data = {\n",
        "            'title': post.title,\n",
        "            'author': str(post.author),\n",
        "            'score': post.score,\n",
        "            'id': post.id,\n",
        "            'url': post.url,\n",
        "            'created_utc': post.created_utc,\n",
        "            'selftext': post.selftext,\n",
        "            'num_comments':post.num_comments\n",
        "        }\n",
        "        posts_data.append(post_data)\n",
        "\n",
        "    return pd.DataFrame(posts_data)\n",
        "# keyword = 'Emotional'\n",
        "posts_df = scrape_posts_by_keyword('shortstories', keyword)\n",
        "posts_df['created_utc'] = pd.to_datetime(posts_df['created_utc'], unit='s')\n",
        "#pre processing the self text for ml\n",
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Remove anything that is not a letter, number, punctuation, or whitespace\n",
        "    text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n",
        "    return text\n",
        "\n",
        "posts_df['selftext'] = posts_df['selftext'].apply(clean_text)\n",
        "\n",
        "\n",
        "posts_df.head()"
      ],
      "metadata": {
        "id": "SbHWBXpJjpCo",
        "outputId": "11ec5bb2-8564-429c-9a27-cc8ff0dc1247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Flair  Count\n",
            "1       Science Fiction     26\n",
            "0               Fantasy     18\n",
            "2          Misc Fiction     11\n",
            "3     Realistic Fiction     11\n",
            "8                Horror     10\n",
            "10               Humour      4\n",
            "4   Speculative Fiction      3\n",
            "9              Thriller      3\n",
            "11        Serial Sunday      3\n",
            "5    Mystery & Suspense      2\n",
            "6               Romance      2\n",
            "7             Off Topic      2\n",
            "14         Micro Monday      2\n",
            "12   Historical Fiction      1\n",
            "13            Meta Post      1\n",
            "15   Action & Adventure      1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title          author  score  \\\n",
              "0  [OT] Micro Monday: Pumpkin Surprise / Comedy H...         OldBayJ      9   \n",
              "1  [SF] I Can’t Stop Watching Four-Legged Comedy,...      RobertSage      3   \n",
              "2             [SF/Comedy] Technology Sucks (Extract)      Forest_ftm      6   \n",
              "3                       [HM][SF] Kill'em With Comedy  patrickryan182     15   \n",
              "4  [NF][Comedy] The elderly gentleman wishes to die.     AnasQiblawi      2   \n",
              "\n",
              "        id                                                url  \\\n",
              "0   xuskl0  https://www.reddit.com/r/shortstories/comments...   \n",
              "1  13sf2sd  https://www.reddit.com/r/shortstories/comments...   \n",
              "2   m49c3e  https://www.reddit.com/r/shortstories/comments...   \n",
              "3   fvv4a1  https://www.reddit.com/r/shortstories/comments...   \n",
              "4   n1b7fr  https://www.reddit.com/r/shortstories/comments...   \n",
              "\n",
              "          created_utc                                           selftext  \\\n",
              "0 2022-10-03 19:15:25  Welcome to Micro Monday\\n\\nHello writers and w...   \n",
              "1 2023-05-26 14:42:31  I Cant Stop Watching FourLegged Comedy, And It...   \n",
              "2 2021-03-13 16:12:04  It started a few weeks ago, and honestly, I th...   \n",
              "3 2020-04-06 08:36:03  Logline In a futuristic world where society is...   \n",
              "4 2021-04-29 18:47:22  There was once a man who was so old that he ap...   \n",
              "\n",
              "   num_comments  \n",
              "0            44  \n",
              "1             1  \n",
              "2             0  \n",
              "3             4  \n",
              "4             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ba1cf8-89c7-431c-bab1-df23fbef5ab5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>selftext</th>\n",
              "      <th>num_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[OT] Micro Monday: Pumpkin Surprise / Comedy H...</td>\n",
              "      <td>OldBayJ</td>\n",
              "      <td>9</td>\n",
              "      <td>xuskl0</td>\n",
              "      <td>https://www.reddit.com/r/shortstories/comments...</td>\n",
              "      <td>2022-10-03 19:15:25</td>\n",
              "      <td>Welcome to Micro Monday\\n\\nHello writers and w...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[SF] I Can’t Stop Watching Four-Legged Comedy,...</td>\n",
              "      <td>RobertSage</td>\n",
              "      <td>3</td>\n",
              "      <td>13sf2sd</td>\n",
              "      <td>https://www.reddit.com/r/shortstories/comments...</td>\n",
              "      <td>2023-05-26 14:42:31</td>\n",
              "      <td>I Cant Stop Watching FourLegged Comedy, And It...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[SF/Comedy] Technology Sucks (Extract)</td>\n",
              "      <td>Forest_ftm</td>\n",
              "      <td>6</td>\n",
              "      <td>m49c3e</td>\n",
              "      <td>https://www.reddit.com/r/shortstories/comments...</td>\n",
              "      <td>2021-03-13 16:12:04</td>\n",
              "      <td>It started a few weeks ago, and honestly, I th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[HM][SF] Kill'em With Comedy</td>\n",
              "      <td>patrickryan182</td>\n",
              "      <td>15</td>\n",
              "      <td>fvv4a1</td>\n",
              "      <td>https://www.reddit.com/r/shortstories/comments...</td>\n",
              "      <td>2020-04-06 08:36:03</td>\n",
              "      <td>Logline In a futuristic world where society is...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[NF][Comedy] The elderly gentleman wishes to die.</td>\n",
              "      <td>AnasQiblawi</td>\n",
              "      <td>2</td>\n",
              "      <td>n1b7fr</td>\n",
              "      <td>https://www.reddit.com/r/shortstories/comments...</td>\n",
              "      <td>2021-04-29 18:47:22</td>\n",
              "      <td>There was once a man who was so old that he ap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ba1cf8-89c7-431c-bab1-df23fbef5ab5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5ba1cf8-89c7-431c-bab1-df23fbef5ab5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5ba1cf8-89c7-431c-bab1-df23fbef5ab5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-568f3e2a-6727-49dd-abc9-2f58d2acd89a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-568f3e2a-6727-49dd-abc9-2f58d2acd89a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-568f3e2a-6727-49dd-abc9-2f58d2acd89a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "posts_df",
              "summary": "{\n  \"name\": \"posts_df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"\\\"Question Fourteen\\\" [comedy, one-shot] \",\n          \"Where Are Good Publishing Magazines/Companies For Novice Writers to Start Printing Their Work?\",\n          \"[HM] How Man Discovered Marijuana: An Accurate Historical Reproduction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"wastedarkcell\",\n          \"Will_Knapp_Comedy\",\n          \"MattJSutherland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 18,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          10,\n          11,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"wemif\",\n          \"h5y1p\",\n          \"6p0gpo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"https://www.reddit.com/r/shortstories/comments/wemif/question_fourteen_comedy_oneshot/\",\n          \"https://www.reddit.com/r/shortstories/comments/h5y1p/where_are_good_publishing_magazinescompanies_for/\",\n          \"https://www.reddit.com/r/shortstories/comments/6p0gpo/hm_how_man_discovered_marijuana_an_accurate/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_utc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2011-05-07 07:17:24\",\n        \"max\": \"2024-01-24 05:46:56\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"2012-07-11 21:19:10\",\n          \"2011-05-07 07:17:24\",\n          \"2017-07-23 09:24:05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selftext\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"A little short comedy story I wrote and then turned into somekind of enhanced audiobook. how we did it Have a look! \",\n          \"Harry was carrying a 15inch barbecue meat feast pizza with stuffed crust and extra cheese.\\n\\nHe had been looking forward to his Friday treat ever since this morning and had spent the whole day at work dreaming of the moment when he would get to dig into the first slice of the delicious pizza, and he had almost rushed to Avenchis Pizzaria after his shift at Sainsco supermarket had finished. \\n\\nHarry put the key in his apartment door and used the oversized pizza box to push the door open.\\n\\nHe carried the pizza into the kitchen and felt his foot connect with something. Something he had completely neglected to notice while he was finding a spot to put his pizza box down.\\n\\nIt was a body.\\n\\nIn fact, it wasnt just any body, it was his body.\\n\\nHarry looked at the offending corpse which wore his face, lying in a messy heap on his kitchen floor, a gaping hole in his chest the obvious clue to his demise. Blood pooled under the deceased corpse and Harry briefly wondered if this would invalidate his rent agreement.\\n\\nHarry slowly blinked. Partly to see if this was a dream, but mostly because he wasnt sure what else to do.\\n\\nHe prodded the body with the tip of his shoe.\\n \\nHey...\\n\\nNothing. The dead body remained annoyingly dead. \\n\\nHarry took a slice of pizza from the box and considered his options as he munched on the gooey cheese and that spicy pepperoni.\\n\\nHe couldnt just leave a dead body in his kitchen, it was not only unsanitary, but it was very much in the way of the fridge.  He also couldnt just call the cops. What would he tell them? Oh hi, officer, theres a dead me in my kitchen, could you come arrest me for killing myself?\\n\\nHarry decided to take matters into his own hands. He had to hide the body somewhere until he could figure out what to do.\\n\\nIt was just then that things got even more complicated.\\n\\nNow dont freak out, but things are about to get even more complicated, a voice said, stating the obvious.\\n\\nHarry looked up into the face of another him. This one was dressed all in black and held a silenced pistol, the kind Harry had seen in movies.\\n\\nUh...whats going on?\\n\\nIm glad you asked that. Thats a very sensible question. The other Harry said. Ill give you the short version There are infinite worlds out there, and we have to kill bad versions of us to stop reality as we know it from imploding\\n\\nThe original Harry nodded. That was a pretty short version.\\n\\nYeah, its hard to explain the full situation when theres a dead you in the room, trust me, I know.\\n\\nSo, you killed him? Original Harry asked.\\n\\nYeah, thats pretty much it.\\n\\nAnd now youre here to kill me?\\n\\nActually, I was planning on recruiting you\\n\\nUh...recruiting me?\\n\\nYes.\\n\\nWhy?\\n\\nThis is universe 54692, and Im sure you know, this galaxy in universe 54692 is set to be swallowed by a massive black hole\\n\\nUh...I didnt know that\\n\\nReally? I thought all the Harrys knew that\\n\\nNope, not me\\n\\nOh, sorry\\n\\nWhen?\\n\\nIn about five minutes\\n\\nWhat!? Original Harry dropped some cheese from his pizza slice onto his foot but, but given the impending death of the galaxy and everything in it, he chose to ignore it.\\n\\nYeah, I know. Bit of a bummer if you ask me.\\n\\nBut, my whole life is here.\\n\\nNot anymore, Im afraid.\\n\\nDammit, I didnt even get to ask Susan out at work\\n\\nIf it makes any difference, in 98.6 percent of universes, she turned you down anyway.\\n\\nOriginal Harry sighed.\\n\\nSo, what do we do? asked original Harry\\n\\nI have a dimensional portal in my pocket.,\\n\\nOf course you do\\n\\nThe other Harry smiled. Youll like this\\n\\nHe reached into his pocket and pulled out a small device. It looked like a pager from the 1980s. A small black box with a green illuminated screen and a couple of buttons on the front. He pressed a button and one side of Harrys living room seemed to bend and twist, becoming a shimmering doorway.\\n\\nThis is a blatant rip off of Rick and Morty pointed out Original Harry You do know that, right?\\n\\nUh, we dont really talk about that, the other Harry said. Grab the Pizza and follow me \\n\\nOriginal Harry picked up the pizza box and followed him through the portal, into a world of infinite possibilities, and infinite Harrys.\\nBehind him, the sky turned a furious dark purple as his apartment, the dead body, his town, the entire planet, and even Avenchis Pizzaria were sucked into the hungry mouth of the black hole. But by that time, Harry had already left this universe.\",\n          \"There was once a man who was so old that he appeared to be almost a hundred years old. He came to a state when he got so weak that he had no strength even to move for himself. But he could not die. He had called to a servant and said, Now I am going to die, so please call a doctor, so that he will help me die. The servant went out and brought a doctor.\\n\\nWhen the doctor came in, the patient said, Doctor please help me to die. I am unable to move even a finger on my own, and I cannot take water in my throat. I am feeling very much aloof from all the world. What I want is that you will help me die.\\n\\nThe doctor examined him and said, I do not see any illness in you. I feel that you are breathing comfortably every breath is as pure as a crystal, and every side effect is undetectable. While I cannot see anything in you, I think that you are not an ordinary human being. So there must be some reason behind my not being able to see anything abnormal in you. Our world has a creature called the vampire, but I cannot see anything resembling a vampire in you.\\n\\nThe patient then said, Please take me to the cemetery, so that you can understand my problem. So the doctor took him to the cemetery. And then they both sat on a bench.\\n\\nAt this time, it was afternoon, there was a bright sun and a clear sky. The doctor was looking at every dead body placed in a grave, and said, Here is a body, and here is another one, this is another one, I see this one and that one! But I cannot see your vampire anywhere! Now please tell me, what is your problem?\\n\\nFinally the old man said, This tree standing here in the cemetery, look at its trunk, branches and leaves. It is pure, strong and high, like a real ancient tree. And when in ancient times it could easily be the shade of a king, now too it can be the shade of a king.\\n\\nIt is after a long time that I have come close to a real ancient tree, and you will not believe it that they say that a Vampire cannot live near this tree. For a long time the old man had hung his head, and when he looked up, there stood the servant before him. He said, Oh servant, you have come, please take me to this tree.\\n\\nThe old man reached out to the trees trunk. He had tears in his eyes. He said, My dear tree, you are alive, I am alive! But that creature, that creature, I would destroy his life. But I know, you are pure, you are immortal, you cannot be killed by a human being. Tears were rolling down his cheeks and he was yearning for the tree. But the servant said, Please look at the time! It is time for you to die, so please come back to your room.\\n\\nThe old man went to his room and ate some food. He took the doctor to the tree and said, You can see it? Tell me, what is it? I feel that it is the most beautiful and the bestlooking tree. But oh, I feel that I am sinking into the ground, like a demon. I feel that I was once a demon with wings, and now I am flat like an earthworm. Please send me to the place where I belong. And this tree, it has such beautiful wealth. You will not believe that this tree once fruited even now if somebody were to throw a stone at it, the tree would give fruit.\\n\\nA long time ago, I had come near this tree with a full stomach! I had knocked on it and asked for a little water. Water and alms were given to me. And I knew that I would never be able to come back again.\\n\\nOh, I have seen plenty of trees and they all had started fruiting again. But this tree, it is stuck.\\n\\nSuddenly, an old woman came out, and she said, What is it you want? Why are you knocking at the tree? And this tree, how does it look? I do not feel that it has any value. But I have read a story, every tree has some value in itself, even the oldest one. Look at this, and look at this. If you enter into your mind, you will come to know the true value it has.\\n\\nThe old woman talked for a long time, but the man did not answer. Then the old woman said, You are old, as it has been said. It is time for you to die. Nine times, there are nine times, when a person dies. That is why they call every nine years, the end of an era.\\n\\nSo it is that time for you to die. You cannot die, but the day has come. Behold, the day has come when you shall die. You do not know what a miracle is. Your wings have mostly disappeared, and there is not any fear in your heart. If you are left alone, you will become a vampire, and you will become a vampire and you will become an old vampire, and you will never die.\\n\\nIn fact, they say that vampires become vampires by eating human beings. This thing is true if you are a vampire, your saliva starts to dry up. That is why a person is afraid that he must rinse his mouth continuously.\\n\\nSo I have come to tell you the way how you can live health and strong. You should believe me.\\n\\nBut there is one thing you must know before you can go to the doctor who will provide you with the information.\\n\\nIt is that a vampire does not really die. When your blood is mixed up with some blood of a young man, your life will become long and perfect.\\n\\nThis thing is true. If you get the blood of a young man mixed with yours, you can live for the next two or three thousand years. To be precise, your life span will be twothird of what it is now.\\n\\nWhat will you get after two or three thousand years? What will you get after three or four thousand years?\\n\\nThe old man saw the old woman standing before him. He had a great surprise in his eyes. But his mouth was wide open. He was just thinking over the old womans words. He could not talk for so long.\\n\\nFinally the old man said, Ha ha, I knew it. I know that it is an old mans blood. But now how can I get it? All heroes have gone, and I am an old man. There is no one to help me. There is no one coming to help me. I have nothing except my two hands. I am an old man. I am tired. I cannot do anything for myself.\\n\\nI can have some rest. Surely I can rest. And people used to say that a man could be entrusted with the business of carrying the dead body of a saint. But in those days, I was of no value, and now there is no one to make me open my eyes.\\n\\nClever people, that is what they call them. But you are sitting before me. By chance I see you. I have run into you. You are an old woman. You are standing in front of my tree. Now it has become dark green.\\n\\nYou say that I have lost my virtues. Yes, that is what you say. But I know my own body. I know my own virtue, I know my own talks. I can talk, I can move my hands.\\n\\nYou say that I am ahead of my time, and I am way ahead of my time, and the people do not know me. Even the people who do not know me, come to enquire about me. They have seen the hue of the my skin.\\n\\nActually, my words are very good. I think Im a great speaker. But I know that I have no chance to live no more .\\n\\n\\nYou want me to live more! But what will I gain by doing that? What gifts will I give? What value will I have? I cannot see any goodness in me. I am just an old man.\\n\\nI know that if even a good tree dies, its value will not be seen the next day.\\n\\nThat is why I say there is a girl who lives nearby, and she is a very good speaker. Maybe she will tell a nice story of me tomorrow. I am tired. Today I have been talking too much. Tomorrow I will get up again.\\n\\ngood bye\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 80,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          80,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "sparksession = SparkSession.builder \\\n",
        "    .appName(\"Reddit Data Processing\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "vmaBaaeKjuQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = sparksession.createDataFrame(posts_df)\n",
        "\n",
        "spark_df.show()"
      ],
      "metadata": {
        "id": "z4q_NVEoj-y3",
        "outputId": "f2ba0155-1c3b-4ef4-ca39-6d0488ae6c51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+\n",
            "|               title|              author|score|     id|                 url|        created_utc|            selftext|num_comments|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+\n",
            "|[MS] Who's really...|      Inevitable_Jex|    6| r463ol|https://www.reddi...|2021-11-28 14:58:38|This is how it st...|           1|\n",
            "|[MF] The Peak of ...|            gammarik|    3| nwvq2z|https://www.reddi...|2021-06-10 19:08:57|The mother climbs...|           4|\n",
            "|[RO] Logic and Em...|          Sensorfire|    5| 2o08mn|https://www.reddi...|2014-12-02 02:43:15|This is my first ...|           4|\n",
            "|[MT] Need help fi...|             Skrot44|    0| 67ib3e|https://www.reddi...|2017-04-25 18:05:00|Hello all, Im her...|           0|\n",
            "|[RO] My short sto...|      MoneyTakerBaby|    6|11kzcuc|https://www.reddi...|2023-03-07 13:28:26|Hello reddit! I j...|           3|\n",
            "|[MF] Studies in E...|          ElkeKerman|    2| 3clpea|https://www.reddi...|2015-07-08 21:52:50|A thin gasping ca...|           0|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    4| 1dvewh|https://www.reddi...|2013-05-07 17:13:52|This, this a stor...|           0|\n",
            "|[UR] Living Color...|Satellite_To_The_Sun|    2| 7h29g1|https://www.reddi...|2017-12-02 11:55:25|John had never ta...|           2|\n",
            "|[HR] The unseen t...|           melon_mel|    1| eid3b7|https://www.reddi...|2020-01-01 03:04:19|This is going to ...|           0|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    1| 1dvzc5|https://www.reddi...|2013-05-07 21:22:45|Well, do you guys...|           0|\n",
            "|Daddy's Little Gi...|          scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|\n",
            "|Flash-Back Short ...|      Jeremiah123098|    1| 1nuypr|https://www.reddi...|2013-10-06 19:47:25|On April 18th, a ...|           0|\n",
            "|[MF] Too Much, No...|    fre_sh_a_v0ca_d0|    1|1b0z75g|https://www.reddi...|2024-02-27 01:30:05|\\r  \\nChapter 1 T...|           2|\n",
            "|Impervious - a sh...|         Mattonicide|    1| 17fbr2|https://www.reddi...|2013-01-28 12:25:07|Liquid bubbles fa...|           0|\n",
            "|      [SF] EMO-DRIVE|        Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|\n",
            "|[SerSun] Serial S...|             OldBayJ|   12|151e7jm|https://www.reddi...|2023-07-16 18:53:47|Welcome to Serial...|          89|\n",
            "|[TH] Canoeing off...|     Serious-Eye7931|    1|17hvuk3|https://www.reddi...|2023-10-27 19:49:22|Life accelerates ...|           1|\n",
            "|[FN] Path of Chan...|             Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|\n",
            "|[SF] The Oddities...|     TrueGodOfHollow|    1|14qehmb|https://www.reddi...|2023-07-04 12:55:54|In the deep of th...|           1|\n",
            "|    [RF] the pointer|          Boris35635|    2|15yqt5q|https://www.reddi...|2023-08-23 02:36:47| As kids we are t...|           2|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Verify the DataFrame structure (Optional but helpful)\n",
        "spark_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETj2rMrkm00A",
        "outputId": "62685cfa-dad4-4bbe-fa07-1dfc7046f589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- title: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- score: long (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            " |-- created_utc: timestamp (nullable = true)\n",
            " |-- selftext: string (nullable = true)\n",
            " |-- num_comments: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your DataFrame has a column named \"text\" for the pipeline\n",
        "# Rename the 'selftext' column to 'text'\n",
        "prepared_df = spark_df.withColumnRenamed(\"selftext\", \"text\")\n"
      ],
      "metadata": {
        "id": "DL7nAPqdk1Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now, apply the sentiment analysis pipeline to the correctly prepared DataFrame\n",
        "result_df = pipeline.transform(prepared_df)\n"
      ],
      "metadata": {
        "id": "Du_0QITam_1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Show the original text and the sentiment result\n",
        "# Assuming the pipeline outputs a column named 'sentiment.result'\n",
        "# Adjust the column names based on the actual output of your pipeline\n",
        "result_df.select(\"title\", \"sentiment.result\").show(truncate=False)"
      ],
      "metadata": {
        "id": "69HvuqobkDy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8adff4-1b0e-4ca3-dc8c-a983faf72cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|title                                                                                                                                                                                                                                                               |result   |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|[MS] Who's really to blame? (Emotions or The Mission?                                                                                                                                                                                                               |[neutral]|\n",
            "|[MF] The Peak of the Mountain - A story about dealing with unwanted emotions                                                                                                                                                                                        |[pos]    |\n",
            "|[RO] Logic and Emotions                                                                                                                                                                                                                                             |[pos]    |\n",
            "|[MT] Need help finding a published short story about emotional abuse                                                                                                                                                                                                |[neg]    |\n",
            "|[RO] My short story of why Pokemon Mystery Dungeon Explorers of Sky will always be the most emotional video game in my lifetime, it's connection with my ex fiancee, and how replaying it has been one of the most intense experiences I've ever had playing a game.|[pos]    |\n",
            "|[MF] Studies in Emotion                                                                                                                                                                                                                                             |[neg]    |\n",
            "|Emotions Overriding Configurations                                                                                                                                                                                                                                  |[pos]    |\n",
            "|[UR] Living Color (From my assignment about emotions in animals)                                                                                                                                                                                                    |[neg]    |\n",
            "|[HR] The unseen truth of the world part 1 - the boy who lost his emotions                                                                                                                                                                                           |[neg]    |\n",
            "|Emotions Overriding Configurations pt. 2                                                                                                                                                                                                                            |[pos]    |\n",
            "|Daddy's Little Girl - An emotional and sinister portrayal (17+ for language)                                                                                                                                                                                        |[neg]    |\n",
            "|Flash-Back Short [Emotional] ( My Girlfriend has wrote this and wants thoughts on it )                                                                                                                                                                              |[neg]    |\n",
            "|[MF] Too Much, Not Enough - Ch. 1                                                                                                                                                                                                                                   |[pos]    |\n",
            "|Impervious - a short story about dealing with overwhelming emotion.                                                                                                                                                                                                 |[pos]    |\n",
            "|[SF] EMO-DRIVE                                                                                                                                                                                                                                                      |[pos]    |\n",
            "|[SerSun] Serial Sunday: Envy!                                                                                                                                                                                                                                       |[pos]    |\n",
            "|[TH] Canoeing off of a Waterfall                                                                                                                                                                                                                                    |[pos]    |\n",
            "|[FN] Path of Change, part 15.                                                                                                                                                                                                                                       |[pos]    |\n",
            "|[SF] The Oddities of the Strange Place                                                                                                                                                                                                                              |[pos]    |\n",
            "|[RF] the pointer                                                                                                                                                                                                                                                    |[neg]    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline2 = PretrainedPipeline(\"analyze_sentimentdl_use_imdb\", lang = \"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxjzejFclqy_",
        "outputId": "50784df8-d39a-48d4-af98-e6dd954a7069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analyze_sentimentdl_use_imdb download started this may take some time.\n",
            "Approx size to download 935.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df2 = pipeline2.transform(prepared_df)\n"
      ],
      "metadata": {
        "id": "yo9bOvt7ltAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_df2.select(\"title\", \"sentiment.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DujblF2fk6-",
        "outputId": "45cdbb29-8e25-45b2-d661-a55b2aefaa6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|title                                                                                                                                                                                                                                                               |result|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|[MS] Who's really to blame? (Emotions or The Mission?                                                                                                                                                                                                               |[neg] |\n",
            "|[MF] The Peak of the Mountain - A story about dealing with unwanted emotions                                                                                                                                                                                        |[pos] |\n",
            "|[RO] Logic and Emotions                                                                                                                                                                                                                                             |[neg] |\n",
            "|[MT] Need help finding a published short story about emotional abuse                                                                                                                                                                                                |[pos] |\n",
            "|[RO] My short story of why Pokemon Mystery Dungeon Explorers of Sky will always be the most emotional video game in my lifetime, it's connection with my ex fiancee, and how replaying it has been one of the most intense experiences I've ever had playing a game.|[pos] |\n",
            "|[MF] Studies in Emotion                                                                                                                                                                                                                                             |[pos] |\n",
            "|Emotions Overriding Configurations                                                                                                                                                                                                                                  |[neg] |\n",
            "|[UR] Living Color (From my assignment about emotions in animals)                                                                                                                                                                                                    |[pos] |\n",
            "|[HR] The unseen truth of the world part 1 - the boy who lost his emotions                                                                                                                                                                                           |[pos] |\n",
            "|Emotions Overriding Configurations pt. 2                                                                                                                                                                                                                            |[neg] |\n",
            "|Daddy's Little Girl - An emotional and sinister portrayal (17+ for language)                                                                                                                                                                                        |[pos] |\n",
            "|Flash-Back Short [Emotional] ( My Girlfriend has wrote this and wants thoughts on it )                                                                                                                                                                              |[pos] |\n",
            "|[MF] Too Much, Not Enough - Ch. 1                                                                                                                                                                                                                                   |[pos] |\n",
            "|Impervious - a short story about dealing with overwhelming emotion.                                                                                                                                                                                                 |[pos] |\n",
            "|[SF] EMO-DRIVE                                                                                                                                                                                                                                                      |[pos] |\n",
            "|[SerSun] Serial Sunday: Envy!                                                                                                                                                                                                                                       |[pos] |\n",
            "|[TH] Canoeing off of a Waterfall                                                                                                                                                                                                                                    |[pos] |\n",
            "|[FN] Path of Change, part 15.                                                                                                                                                                                                                                       |[neg] |\n",
            "|[SF] The Oddities of the Strange Place                                                                                                                                                                                                                              |[pos] |\n",
            "|[RF] the pointer                                                                                                                                                                                                                                                    |[neg] |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Extract sentiment and sentiment score from the first pipeline's results\n",
        "test1 = result_df.withColumn(\"sentiment1\", expr(\"sentiment.result[0]\"))\n",
        "# Assuming a way to calculate sentiment score1, as Spark NLP's output format varies\n",
        "\n",
        "# Extract sentiment and sentiment score from the second pipeline's results\n",
        "test2 = result_df2.withColumn(\"sentiment2\", expr(\"sentiment.result[0]\"))\n",
        "# Assuming a way to calculate sentiment score2\n"
      ],
      "metadata": {
        "id": "tP0UTt-SgUZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHloiQBwOZ36",
        "outputId": "7a812b86-0392-4734-9c7a-2eaa46f4b638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|               title|              author|score|     id|                 url|        created_utc|                text|num_comments|            document|            sentence|              tokens|     word_embeddings| sentence_embeddings|           sentiment|sentiment1|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|[MS] Who's really...|      Inevitable_Jex|    6| r463ol|https://www.reddi...|2021-11-28 14:58:38|This is how it st...|           1|[{document, 0, 11...|[{document, 0, 21...|[{token, 0, 3, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 11...|   neutral|\n",
            "|[MF] The Peak of ...|            gammarik|    3| nwvq2z|https://www.reddi...|2021-06-10 19:08:57|The mother climbs...|           4|[{document, 0, 51...|[{document, 0, 60...|[{token, 0, 2, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 51...|       pos|\n",
            "|[RO] Logic and Em...|          Sensorfire|    5| 2o08mn|https://www.reddi...|2014-12-02 02:43:15|This is my first ...|           4|[{document, 0, 23...|[{document, 0, 22...|[{token, 0, 3, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 23...|       pos|\n",
            "|[MT] Need help fi...|             Skrot44|    0| 67ib3e|https://www.reddi...|2017-04-25 18:05:00|Hello all, Im her...|           0|[{document, 0, 38...|[{document, 0, 34...|[{token, 0, 4, He...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 38...|       neg|\n",
            "|[RO] My short sto...|      MoneyTakerBaby|    6|11kzcuc|https://www.reddi...|2023-03-07 13:28:26|Hello reddit! I j...|           3|[{document, 0, 42...|[{document, 0, 12...|[{token, 0, 4, He...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 42...|       pos|\n",
            "|[MF] Studies in E...|          ElkeKerman|    2| 3clpea|https://www.reddi...|2015-07-08 21:52:50|A thin gasping ca...|           0|[{document, 0, 19...|[{document, 0, 80...|[{token, 0, 0, A,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 19...|       neg|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    4| 1dvewh|https://www.reddi...|2013-05-07 17:13:52|This, this a stor...|           0|[{document, 0, 43...|[{document, 0, 91...|[{token, 0, 3, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 43...|       pos|\n",
            "|[UR] Living Color...|Satellite_To_The_Sun|    2| 7h29g1|https://www.reddi...|2017-12-02 11:55:25|John had never ta...|           2|[{document, 0, 31...|[{document, 0, 11...|[{token, 0, 3, Jo...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 31...|       neg|\n",
            "|[HR] The unseen t...|           melon_mel|    1| eid3b7|https://www.reddi...|2020-01-01 03:04:19|This is going to ...|           0|[{document, 0, 49...|[{document, 0, 16...|[{token, 0, 3, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 49...|       neg|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    1| 1dvzc5|https://www.reddi...|2013-05-07 21:22:45|Well, do you guys...|           0|[{document, 0, 26...|[{document, 0, 32...|[{token, 0, 3, We...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 26...|       pos|\n",
            "|Daddy's Little Gi...|          scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|[{document, 0, 98...|[{document, 0, 32...|[{token, 0, 3, Th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 98...|       neg|\n",
            "|Flash-Back Short ...|      Jeremiah123098|    1| 1nuypr|https://www.reddi...|2013-10-06 19:47:25|On April 18th, a ...|           0|[{document, 0, 41...|[{document, 0, 86...|[{token, 0, 1, On...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 41...|       neg|\n",
            "|[MF] Too Much, No...|    fre_sh_a_v0ca_d0|    1|1b0z75g|https://www.reddi...|2024-02-27 01:30:05|\\r  \\nChapter 1 T...|           2|[{document, 0, 44...|[{document, 4, 74...|[{token, 4, 10, C...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 44...|       pos|\n",
            "|Impervious - a sh...|         Mattonicide|    1| 17fbr2|https://www.reddi...|2013-01-28 12:25:07|Liquid bubbles fa...|           0|[{document, 0, 27...|[{document, 0, 54...|[{token, 0, 5, Li...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 27...|       pos|\n",
            "|      [SF] EMO-DRIVE|        Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|[{document, 0, 34...|[{document, 0, 21...|[{token, 0, 4, Ti...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 34...|       pos|\n",
            "|[SerSun] Serial S...|             OldBayJ|   12|151e7jm|https://www.reddi...|2023-07-16 18:53:47|Welcome to Serial...|          89|[{document, 0, 78...|[{document, 0, 24...|[{token, 0, 6, We...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 78...|       pos|\n",
            "|[TH] Canoeing off...|     Serious-Eye7931|    1|17hvuk3|https://www.reddi...|2023-10-27 19:49:22|Life accelerates ...|           1|[{document, 0, 68...|[{document, 0, 39...|[{token, 0, 3, Li...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 68...|       pos|\n",
            "|[FN] Path of Chan...|             Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|[{document, 0, 15...|[{document, 0, 56...|[{token, 0, 4, Af...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 15...|       pos|\n",
            "|[SF] The Oddities...|     TrueGodOfHollow|    1|14qehmb|https://www.reddi...|2023-07-04 12:55:54|In the deep of th...|           1|[{document, 0, 65...|[{document, 0, 13...|[{token, 0, 1, In...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 65...|       pos|\n",
            "|    [RF] the pointer|          Boris35635|    2|15yqt5q|https://www.reddi...|2023-08-23 02:36:47| As kids we are t...|           2|[{document, 0, 44...|[{document, 1, 64...|[{token, 1, 2, As...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 44...|       neg|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l8zTcVCObIw",
        "outputId": "a5802298-8a36-41e2-ca25-10bef25a2529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "|               title|              author|score|     id|                 url|        created_utc|                text|num_comments|            document| sentence_embeddings|           sentiment|sentiment2|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "|[MS] Who's really...|      Inevitable_Jex|    6| r463ol|https://www.reddi...|2021-11-28 14:58:38|This is how it st...|           1|[{document, 0, 11...|[{sentence_embedd...|[{category, 0, 11...|       neg|\n",
            "|[MF] The Peak of ...|            gammarik|    3| nwvq2z|https://www.reddi...|2021-06-10 19:08:57|The mother climbs...|           4|[{document, 0, 51...|[{sentence_embedd...|[{category, 0, 51...|       pos|\n",
            "|[RO] Logic and Em...|          Sensorfire|    5| 2o08mn|https://www.reddi...|2014-12-02 02:43:15|This is my first ...|           4|[{document, 0, 23...|[{sentence_embedd...|[{category, 0, 23...|       neg|\n",
            "|[MT] Need help fi...|             Skrot44|    0| 67ib3e|https://www.reddi...|2017-04-25 18:05:00|Hello all, Im her...|           0|[{document, 0, 38...|[{sentence_embedd...|[{category, 0, 38...|       pos|\n",
            "|[RO] My short sto...|      MoneyTakerBaby|    6|11kzcuc|https://www.reddi...|2023-03-07 13:28:26|Hello reddit! I j...|           3|[{document, 0, 42...|[{sentence_embedd...|[{category, 0, 42...|       pos|\n",
            "|[MF] Studies in E...|          ElkeKerman|    2| 3clpea|https://www.reddi...|2015-07-08 21:52:50|A thin gasping ca...|           0|[{document, 0, 19...|[{sentence_embedd...|[{category, 0, 19...|       pos|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    4| 1dvewh|https://www.reddi...|2013-05-07 17:13:52|This, this a stor...|           0|[{document, 0, 43...|[{sentence_embedd...|[{category, 0, 43...|       neg|\n",
            "|[UR] Living Color...|Satellite_To_The_Sun|    2| 7h29g1|https://www.reddi...|2017-12-02 11:55:25|John had never ta...|           2|[{document, 0, 31...|[{sentence_embedd...|[{category, 0, 31...|       pos|\n",
            "|[HR] The unseen t...|           melon_mel|    1| eid3b7|https://www.reddi...|2020-01-01 03:04:19|This is going to ...|           0|[{document, 0, 49...|[{sentence_embedd...|[{category, 0, 49...|       pos|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    1| 1dvzc5|https://www.reddi...|2013-05-07 21:22:45|Well, do you guys...|           0|[{document, 0, 26...|[{sentence_embedd...|[{category, 0, 26...|       neg|\n",
            "|Daddy's Little Gi...|          scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|[{document, 0, 98...|[{sentence_embedd...|[{category, 0, 98...|       pos|\n",
            "|Flash-Back Short ...|      Jeremiah123098|    1| 1nuypr|https://www.reddi...|2013-10-06 19:47:25|On April 18th, a ...|           0|[{document, 0, 41...|[{sentence_embedd...|[{category, 0, 41...|       pos|\n",
            "|[MF] Too Much, No...|    fre_sh_a_v0ca_d0|    1|1b0z75g|https://www.reddi...|2024-02-27 01:30:05|\\r  \\nChapter 1 T...|           2|[{document, 0, 44...|[{sentence_embedd...|[{category, 0, 44...|       pos|\n",
            "|Impervious - a sh...|         Mattonicide|    1| 17fbr2|https://www.reddi...|2013-01-28 12:25:07|Liquid bubbles fa...|           0|[{document, 0, 27...|[{sentence_embedd...|[{category, 0, 27...|       pos|\n",
            "|      [SF] EMO-DRIVE|        Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|[{document, 0, 34...|[{sentence_embedd...|[{category, 0, 34...|       pos|\n",
            "|[SerSun] Serial S...|             OldBayJ|   12|151e7jm|https://www.reddi...|2023-07-16 18:53:47|Welcome to Serial...|          89|[{document, 0, 78...|[{sentence_embedd...|[{category, 0, 78...|       pos|\n",
            "|[TH] Canoeing off...|     Serious-Eye7931|    1|17hvuk3|https://www.reddi...|2023-10-27 19:49:22|Life accelerates ...|           1|[{document, 0, 68...|[{sentence_embedd...|[{category, 0, 68...|       pos|\n",
            "|[FN] Path of Chan...|             Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|[{document, 0, 15...|[{sentence_embedd...|[{category, 0, 15...|       neg|\n",
            "|[SF] The Oddities...|     TrueGodOfHollow|    1|14qehmb|https://www.reddi...|2023-07-04 12:55:54|In the deep of th...|           1|[{document, 0, 65...|[{sentence_embedd...|[{category, 0, 65...|       pos|\n",
            "|    [RF] the pointer|          Boris35635|    2|15yqt5q|https://www.reddi...|2023-08-23 02:36:47| As kids we are t...|           2|[{document, 0, 44...|[{sentence_embedd...|[{category, 0, 44...|       neg|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test1.select(\"title\", \"sentiment\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzfiloQ0OsyK",
        "outputId": "537d128d-c5eb-4444-adcc-68ac06e36d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
            "|title                                                                                                                                                                                                                                                               |sentiment                                                                                |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
            "|[MS] Who's really to blame? (Emotions or The Mission?                                                                                                                                                                                                               |[{category, 0, 11936, neutral, {sentence -> 0, pos -> 0.44162267, neg -> 0.5583773}, []}]|\n",
            "|[MF] The Peak of the Mountain - A story about dealing with unwanted emotions                                                                                                                                                                                        |[{category, 0, 5157, pos, {sentence -> 0, pos -> 0.99569476, neg -> 0.0043052505}, []}]  |\n",
            "|[RO] Logic and Emotions                                                                                                                                                                                                                                             |[{category, 0, 2304, pos, {sentence -> 0, pos -> 0.9791074, neg -> 0.020892603}, []}]    |\n",
            "|[MT] Need help finding a published short story about emotional abuse                                                                                                                                                                                                |[{category, 0, 383, neg, {sentence -> 0, pos -> 0.14983611, neg -> 0.8501639}, []}]      |\n",
            "|[RO] My short story of why Pokemon Mystery Dungeon Explorers of Sky will always be the most emotional video game in my lifetime, it's connection with my ex fiancee, and how replaying it has been one of the most intense experiences I've ever had playing a game.|[{category, 0, 4203, pos, {sentence -> 0, pos -> 0.98266566, neg -> 0.017334355}, []}]   |\n",
            "|[MF] Studies in Emotion                                                                                                                                                                                                                                             |[{category, 0, 1914, neg, {sentence -> 0, pos -> 0.002719636, neg -> 0.99728036}, []}]   |\n",
            "|Emotions Overriding Configurations                                                                                                                                                                                                                                  |[{category, 0, 4381, pos, {sentence -> 0, pos -> 0.94844973, neg -> 0.05155026}, []}]    |\n",
            "|[UR] Living Color (From my assignment about emotions in animals)                                                                                                                                                                                                    |[{category, 0, 3116, neg, {sentence -> 0, pos -> 0.072371036, neg -> 0.92762893}, []}]   |\n",
            "|[HR] The unseen truth of the world part 1 - the boy who lost his emotions                                                                                                                                                                                           |[{category, 0, 4946, neg, {sentence -> 0, pos -> 0.04252631, neg -> 0.9574737}, []}]     |\n",
            "|Emotions Overriding Configurations pt. 2                                                                                                                                                                                                                            |[{category, 0, 2661, pos, {sentence -> 0, pos -> 0.96342224, neg -> 0.036577757}, []}]   |\n",
            "|Daddy's Little Girl - An emotional and sinister portrayal (17+ for language)                                                                                                                                                                                        |[{category, 0, 9813, neg, {sentence -> 0, pos -> 0.009914255, neg -> 0.9900857}, []}]    |\n",
            "|Flash-Back Short [Emotional] ( My Girlfriend has wrote this and wants thoughts on it )                                                                                                                                                                              |[{category, 0, 4184, neg, {sentence -> 0, pos -> 0.1632027, neg -> 0.83679736}, []}]     |\n",
            "|[MF] Too Much, Not Enough - Ch. 1                                                                                                                                                                                                                                   |[{category, 0, 4419, pos, {sentence -> 0, pos -> 0.9891205, neg -> 0.0108795315}, []}]   |\n",
            "|Impervious - a short story about dealing with overwhelming emotion.                                                                                                                                                                                                 |[{category, 0, 2744, pos, {sentence -> 0, pos -> 0.9998447, neg -> 1.5527094E-4}, []}]   |\n",
            "|[SF] EMO-DRIVE                                                                                                                                                                                                                                                      |[{category, 0, 3483, pos, {sentence -> 0, pos -> 0.97052675, neg -> 0.0294733}, []}]     |\n",
            "|[SerSun] Serial Sunday: Envy!                                                                                                                                                                                                                                       |[{category, 0, 7880, pos, {sentence -> 0, pos -> 0.80891556, neg -> 0.19108447}, []}]    |\n",
            "|[TH] Canoeing off of a Waterfall                                                                                                                                                                                                                                    |[{category, 0, 6889, pos, {sentence -> 0, pos -> 0.7011102, neg -> 0.2988898}, []}]      |\n",
            "|[FN] Path of Change, part 15.                                                                                                                                                                                                                                       |[{category, 0, 15852, pos, {sentence -> 0, pos -> 0.9242927, neg -> 0.07570725}, []}]    |\n",
            "|[SF] The Oddities of the Strange Place                                                                                                                                                                                                                              |[{category, 0, 6515, pos, {sentence -> 0, pos -> 0.8112965, neg -> 0.18870348}, []}]     |\n",
            "|[RF] the pointer                                                                                                                                                                                                                                                    |[{category, 0, 4430, neg, {sentence -> 0, pos -> 0.12906642, neg -> 0.87093365}, []}]    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWb-ahYySBh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the original DataFrame with the first pipeline's results\n",
        "combined_df = spark_df.join(test1.select(\"title\", \"sentiment1\"), \"title\")\n",
        "\n",
        "# Join the combined DataFrame with the second pipeline's results\n",
        "final_df = combined_df.join(test2.select(\"title\", \"sentiment2\"), \"title\")\n"
      ],
      "metadata": {
        "id": "yl05U3irO33K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i0vXbOuRkGA",
        "outputId": "a7552359-b6a9-47ee-a5fb-5d9276582159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+\n",
            "|               title|              author|score|     id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+\n",
            "|      [SF] EMO-DRIVE|        Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|       pos|       pos|\n",
            "|[OT] Micro Monday...|             OldBayJ|    7|18as6of|https://www.reddi...|2023-12-04 19:35:09|Welcome to Micro ...|          17|       pos|       pos|\n",
            "|[OT] Micro Monday...|             OldBayJ|   14|12pvw78|https://www.reddi...|2023-04-17 20:38:12|Welcome to Micro ...|          32|       pos|       pos|\n",
            "|[FN] Path of Chan...|             Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|       pos|       neg|\n",
            "|Daddy's Little Gi...|          scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|       neg|       pos|\n",
            "|[RO] My short sto...|      MoneyTakerBaby|    6|11kzcuc|https://www.reddi...|2023-03-07 13:28:26|Hello reddit! I j...|           3|       pos|       pos|\n",
            "|[SerSun] Serial S...|             OldBayJ|   12|151e7jm|https://www.reddi...|2023-07-16 18:53:47|Welcome to Serial...|          89|       pos|       pos|\n",
            "|[SF] The Oddities...|     TrueGodOfHollow|    1|14qehmb|https://www.reddi...|2023-07-04 12:55:54|In the deep of th...|           1|       pos|       pos|\n",
            "|[MS] Who's really...|      Inevitable_Jex|    6| r463ol|https://www.reddi...|2021-11-28 14:58:38|This is how it st...|           1|   neutral|       neg|\n",
            "|[UR] Living Color...|Satellite_To_The_Sun|    2| 7h29g1|https://www.reddi...|2017-12-02 11:55:25|John had never ta...|           2|       neg|       pos|\n",
            "|[MF] Too Much, No...|    fre_sh_a_v0ca_d0|    1|1b0z75g|https://www.reddi...|2024-02-27 01:30:05|\\r  \\nChapter 1 T...|           2|       pos|       pos|\n",
            "|[MF] In The Midst...|      MachineHoliday|    0|1azz776|https://www.reddi...|2024-02-25 21:16:29|As Stephen walked...|           2|       neg|       pos|\n",
            "|Impervious - a sh...|         Mattonicide|    1| 17fbr2|https://www.reddi...|2013-01-28 12:25:07|Liquid bubbles fa...|           0|       pos|       pos|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    4| 1dvewh|https://www.reddi...|2013-05-07 17:13:52|This, this a stor...|           0|       pos|       neg|\n",
            "|[MF] The Peak of ...|            gammarik|    3| nwvq2z|https://www.reddi...|2021-06-10 19:08:57|The mother climbs...|           4|       pos|       pos|\n",
            "|[NF] A Life of Ch...|          Phyla_Arau|    1|13hunne|https://www.reddi...|2023-05-15 02:16:38|Days pass. Nothin...|           2|       pos|       neg|\n",
            "|Flash-Back Short ...|      Jeremiah123098|    1| 1nuypr|https://www.reddi...|2013-10-06 19:47:25|On April 18th, a ...|           0|       neg|       pos|\n",
            "|    [RF] the pointer|          Boris35635|    2|15yqt5q|https://www.reddi...|2023-08-23 02:36:47| As kids we are t...|           2|       neg|       neg|\n",
            "|[OT] Micro Monday...|             OldBayJ|    7|17zxi9t|https://www.reddi...|2023-11-20 20:04:00|Welcome to Micro ...|          34|       pos|       pos|\n",
            "|[MF] Studies in E...|          ElkeKerman|    2| 3clpea|https://www.reddi...|2015-07-08 21:52:50|A thin gasping ca...|           0|       neg|       pos|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.functions import lit\n"
      ],
      "metadata": {
        "id": "PuavVdKUTcMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def analyze_keyword(keywordforscraping):\n",
        "#     # Scrape posts\n",
        "#     posts_df = scrape_posts_by_keyword('shortstories', keywordforscraping)\n",
        "#     posts_df['created_utc'] = pd.to_datetime(posts_df['created_utc'], unit='s')\n",
        "\n",
        "#     def clean_text(text):# Remove URLs\n",
        "\n",
        "#       text = re.sub(r'http\\S+', '', text)\n",
        "#       # Remove anything that is not a letter, number, punctuation, or whitespace\n",
        "#       text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n",
        "#       return text\n",
        "\n",
        "#     posts_df['selftext'] = posts_df['selftext'].apply(clean_text)\n",
        "\n",
        "\n",
        "#     # Convert to Spark DataFrame\n",
        "#     spark_df = spark.createDataFrame(posts_df)\n",
        "\n",
        "#     # # Preprocess text\n",
        "#     # spark_df = spark_df.withColumn(\"clean_text\", clean_text_udf(col(\"selftext\")))\n",
        "\n",
        "#     # Rename column for sentiment analysis\n",
        "#     prepared_df = spark_df.withColumnRenamed(\"selftext\", \"text\")\n",
        "\n",
        "#     # Analyze sentiment with both pipelines\n",
        "#     result_df1 = pipeline.transform(prepared_df)\n",
        "#     result_df2 = pipeline2.transform(prepared_df)\n",
        "\n",
        "#       # Extract sentiment and sentiment score from the first pipeline's results\n",
        "#     test1 = result_df.withColumn(\"sentiment1\", expr(\"sentiment.result[0]\"))\n",
        "#     # Assuming a way to calculate sentiment score1, as Spark NLP's output format varies\n",
        "\n",
        "#     # Extract sentiment and sentiment score from the second pipeline's results\n",
        "#     test2 = result_df2.withColumn(\"sentiment2\", expr(\"sentiment.result[0]\"))\n",
        "#     # Assuming a way to calculate sentiment score2\n",
        "#     # Join the original DataFrame with the first pipeline's results\n",
        "#     combined_df = spark_df.join(test1.select(\"title\", \"sentiment1\"), \"title\")\n",
        "\n",
        "#     # Join the combined DataFrame with the second pipeline's results\n",
        "#     final_df = combined_df.join(test2.select(\"title\", \"sentiment2\"), \"title\")\n",
        "#     final_df = final_df.withColumn(\"keyword\", lit(keywordforscraping))\n",
        "#     # Your existing code to scrape, process, and analyze sentiment...\n",
        "#     print(f\"Processing keyword: {keywordforscraping}\")\n",
        "#     # Assuming the final DataFrame for this keyword is named `result_df`\n",
        "#     print(f\"Number of posts for {keywordforscraping}: {final_df.count()}\")\n",
        "\n",
        "#     final_df.show(5)\n",
        "#     return final_df\n"
      ],
      "metadata": {
        "id": "Ffk_21baSS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_keyword(keywordforscraping):\n",
        "    print(f\"Starting processing for keyword: {keywordforscraping}\")\n",
        "    try:\n",
        "        # Your existing code to scrape, process, and analyze sentiment...\n",
        "        # For example:\n",
        "        def scrape_posts_by_keyword(subreddit_name, keyword, limit=50):\n",
        "            subreddit = reddit.subreddit(subreddit_name)\n",
        "            posts_data = []\n",
        "\n",
        "            for post in subreddit.search(keyword, limit=limit):\n",
        "                post_data = {\n",
        "                    'title': post.title,\n",
        "                    'author': str(post.author),\n",
        "                    'score': post.score,\n",
        "                    'id': post.id,\n",
        "                    'url': post.url,\n",
        "                    'created_utc': post.created_utc,\n",
        "                    'selftext': post.selftext,\n",
        "                    'num_comments':post.num_comments\n",
        "                }\n",
        "                posts_data.append(post_data)\n",
        "\n",
        "            return pd.DataFrame(posts_data)\n",
        "        # posts_df = scrape_posts_by_keyword('shortstories', keyword)\n",
        "        posts_df = scrape_posts_by_keyword('shortstories', keywordforscraping)\n",
        "        if posts_df.empty:\n",
        "            print(f\"No posts found for keyword: {keywordforscraping}\")\n",
        "            return None  # Return None or an empty DataFrame\n",
        "        posts_df['created_utc'] = pd.to_datetime(posts_df['created_utc'], unit='s')\n",
        "\n",
        "        def clean_text(text):# Remove URLs\n",
        "\n",
        "          text = re.sub(r'http\\S+', '', text)\n",
        "          # Remove anything that is not a letter, number, punctuation, or whitespace\n",
        "          text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n",
        "          return text\n",
        "\n",
        "        posts_df['selftext'] = posts_df['selftext'].apply(clean_text)\n",
        "\n",
        "        # Convert to Spark DataFrame, preprocess, analyze sentiment, etc.\n",
        "        # Example:\n",
        "        spark_df = spark.createDataFrame(posts_df)\n",
        "        print(f\"Converted to Spark DataFrame for keyword: {keywordforscraping}, Number of posts: {spark_df.count()}\")\n",
        "\n",
        "        # Assume you have the rest of your pipeline here\n",
        "        # Rename column for sentiment analysis\n",
        "        prepared_df = spark_df.withColumnRenamed(\"selftext\", \"text\")\n",
        "\n",
        "        # Analyze sentiment with both pipelines\n",
        "        result_df1 = pipeline.transform(prepared_df)\n",
        "        result_df2 = pipeline2.transform(prepared_df)\n",
        "\n",
        "          # Extract sentiment and sentiment score from the first pipeline's results\n",
        "        test1 = result_df1.withColumn(\"sentiment1\", expr(\"sentiment.result[0]\"))\n",
        "        # Assuming a way to calculate sentiment score1, as Spark NLP's output format varies\n",
        "\n",
        "        # Extract sentiment and sentiment score from the second pipeline's results\n",
        "        test2 = result_df2.withColumn(\"sentiment2\", expr(\"sentiment.result[0]\"))\n",
        "        # Assuming a way to calculate sentiment score2\n",
        "        # Join the original DataFrame with the first pipeline's results\n",
        "        combined_df = spark_df.join(test1.select(\"title\", \"sentiment1\"), \"title\")\n",
        "\n",
        "        # Join the combined DataFrame with the second pipeline's results\n",
        "        final_df = combined_df.join(test2.select(\"title\", \"sentiment2\"), \"title\")\n",
        "        final_df = final_df.withColumn(\"keyword\", lit(keywordforscraping))\n",
        "        # Your existing code to scrape, process, and analyze sentiment...\n",
        "        print(f\"Processing keyword: {keywordforscraping}\")\n",
        "        # Assuming the final DataFrame for this keyword is named `result_df`\n",
        "        print(f\"Number of posts for {keywordforscraping}: {final_df.count()}\")\n",
        "\n",
        "        final_df.show(5)\n",
        "        print(f\"Completed processing for keyword: {keywordforscraping}\")\n",
        "        return final_df  # Or your final DataFrame for this keyword\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing keyword {keywordforscraping}: {e}\")\n",
        "        return None  # Return None or an empty DataFrame on error"
      ],
      "metadata": {
        "id": "coB3vqgCdQc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [\"Emotional\", \"adventure\", \"mystery\",\"horror\",\"comedy\"]\n",
        "dfs = [analyze_keyword(key) for key in keywords]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTUZQtrDTO0M",
        "outputId": "a39f101a-c1b9-42dd-af10-490ff246b46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing for keyword: Emotional\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to Spark DataFrame for keyword: Emotional, Number of posts: 50\n",
            "Processing keyword: Emotional\n",
            "Number of posts for Emotional: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|               title|      author|score|     id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|  keyword|\n",
            "+--------------------+------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|      [SF] EMO-DRIVE|Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|       pos|       pos|Emotional|\n",
            "|[OT] Micro Monday...|     OldBayJ|    5|18as6of|https://www.reddi...|2023-12-04 19:35:09|Welcome to Micro ...|          17|       pos|       pos|Emotional|\n",
            "|[OT] Micro Monday...|     OldBayJ|   14|12pvw78|https://www.reddi...|2023-04-17 20:38:12|Welcome to Micro ...|          32|       pos|       pos|Emotional|\n",
            "|[FN] Path of Chan...|     Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|       pos|       neg|Emotional|\n",
            "|Daddy's Little Gi...|  scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|       neg|       pos|Emotional|\n",
            "+--------------------+------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Completed processing for keyword: Emotional\n",
            "Starting processing for keyword: adventure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to Spark DataFrame for keyword: adventure, Number of posts: 50\n",
            "Processing keyword: adventure\n",
            "Number of posts for adventure: 170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|               title|        author|score|     id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|  keyword|\n",
            "+--------------------+--------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|[FN] <The Adventu...|   Jayn_Newell|    3|1387pw5|https://www.reddi...|2023-05-05 02:21:13|Cliff hung back a...|           2|       neg|       neg|adventure|\n",
            "|[HM] The Adventur...|      TF-Scott|    2|18ae72x|https://www.reddi...|2023-12-04 06:23:51|This is one in a ...|           1|       neg|       neg|adventure|\n",
            "|[SF] Pale Terry, ...|scare_in_a_box|    2|14lj5b9|https://www.reddi...|2023-06-28 19:48:17|The receiver crac...|           1|       neg|       neg|adventure|\n",
            "|[RO] Three fish a...| marsh20202020|    2| zt0huj|https://www.reddi...|2022-12-22 23:33:53|Lola, Timmy, and ...|           1|       pos|       pos|adventure|\n",
            "|[SerSun] Serial S...|    Cody_Fox23|   14|14clbd4|https://www.reddi...|2023-06-18 14:04:36|Welcome to Serial...|          94|       pos|       pos|adventure|\n",
            "+--------------------+--------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Completed processing for keyword: adventure\n",
            "Starting processing for keyword: mystery\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to Spark DataFrame for keyword: mystery, Number of posts: 50\n",
            "Processing keyword: mystery\n",
            "Number of posts for mystery: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|               title| author|score|     id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|keyword|\n",
            "+--------------------+-------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|[SF] Mechanized M...|Aftel43|    1|18bdkyl|https://www.reddi...|2023-12-05 14:49:20|I get up from bed...|           0|       neg|       neg|mystery|\n",
            "|[SF] Mechanized M...|Aftel43|    1|18bdkyl|https://www.reddi...|2023-12-05 14:49:20|I get up from bed...|           0|       neg|       neg|mystery|\n",
            "|[SF] Mechanized M...|Aftel43|    1|18bdkyl|https://www.reddi...|2023-12-05 14:49:20|I get up from bed...|           0|       neg|       neg|mystery|\n",
            "|[SF] Mechanized M...|Aftel43|    1|18bdkwq|https://www.reddi...|2023-12-05 14:49:15|I get up from bed...|           0|       neg|       neg|mystery|\n",
            "|[SF] Mechanized M...|Aftel43|    1|18bdkwq|https://www.reddi...|2023-12-05 14:49:15|I get up from bed...|           0|       neg|       neg|mystery|\n",
            "+--------------------+-------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Completed processing for keyword: mystery\n",
            "Starting processing for keyword: horror\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to Spark DataFrame for keyword: horror, Number of posts: 50\n",
            "Processing keyword: horror\n",
            "Number of posts for horror: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|               title|            author|score|    id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|keyword|\n",
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|[HR] Museum Horro...|   hhhhiiiiiiiiiii|   10|qe8w5x|https://www.reddi...|2021-10-23 17:07:05|I was alone in th...|           3|       neg|       neg| horror|\n",
            "|[HR] Treehouse of...|  BigNickOnTheDrum|    2|q5bc0p|https://www.reddi...|2021-10-10 16:27:01|Bart is upset tha...|           3|       pos|   neutral| horror|\n",
            "|[HR] Horror/Fanta...|clayvermulmfiction|   13|mqr3li|https://www.reddi...|2021-04-14 13:56:43|HR Seismic Part 1...|           4|       pos|       neg| horror|\n",
            "|[OT] Roundtable T...|           OldBayJ|    9|xxao92|https://www.reddi...|2022-10-06 17:15:28|Welcome to Roundt...|          21|       pos|       pos| horror|\n",
            "|[OT] Micro Monday...|           OldBayJ|   11|xuskl0|https://www.reddi...|2022-10-03 19:15:25|Welcome to Micro ...|          44|       pos|       pos| horror|\n",
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Completed processing for keyword: horror\n",
            "Starting processing for keyword: comedy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to Spark DataFrame for keyword: comedy, Number of posts: 50\n",
            "Processing keyword: comedy\n",
            "Number of posts for comedy: 50\n",
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|               title|            author|score|    id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|keyword|\n",
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "|[RF] The Human Co...|          vladbrat|    2|2n0cdh|http://www.imagec...|2014-11-21 19:00:38|                    |           0|       neg|      null| comedy|\n",
            "|[RF] The Human Co...|          xidanphi|    1|2sepj7|http://www.imagec...|2015-01-14 15:39:14|                    |           0|       neg|       pos| comedy|\n",
            "|[RF] The Human Co...|          xidanphi|    3|2nhgev|http://www.imagec...|2014-11-26 15:32:43|                    |           1|       neg|      null| comedy|\n",
            "|[SF] Schrodinger'...|abrahamsimpsonpass|    2|a9agjb|https://www.reddi...|2018-12-25 00:42:09|A murmur reverber...|           0|       neg|      null| comedy|\n",
            "|\"The Hailing Taxi...|          adumbrow|    1|10wyf7|http://www.stumbl...|2012-10-04 02:57:37|                    |           0|       neg|      null| comedy|\n",
            "+--------------------+------------------+-----+------+--------------------+-------------------+--------------------+------------+----------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Completed processing for keyword: comedy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Merge all DataFrames into one\n",
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "def unionAll(*dfs):\n",
        "    return reduce(DataFrame.unionAll, dfs)\n",
        "\n",
        "combine_final_df = unionAll(*dfs)\n"
      ],
      "metadata": {
        "id": "EHqNaq17aI5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52OP0fR-ZTty",
        "outputId": "3b440417-11e0-4362-afc3-d82fec75c8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[title: string, author: string, score: bigint, id: string, url: string, created_utc: timestamp, selftext: string, num_comments: bigint, sentiment1: string, sentiment2: string, keyword: string]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combine_final_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUsYnnV2UAWP",
        "outputId": "387b39ac-9a7e-4262-8693-df1594e0060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|               title|              author|score|     id|                 url|        created_utc|            selftext|num_comments|sentiment1|sentiment2|  keyword|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "|      [SF] EMO-DRIVE|        Daplugottawa|    2|11unsno|https://www.reddi...|2023-03-18 12:56:42|Title EmoDrive Th...|           1|       pos|       pos|Emotional|\n",
            "|[OT] Micro Monday...|             OldBayJ|    5|18as6of|https://www.reddi...|2023-12-04 19:35:09|Welcome to Micro ...|          17|       pos|       pos|Emotional|\n",
            "|[OT] Micro Monday...|             OldBayJ|   14|12pvw78|https://www.reddi...|2023-04-17 20:38:12|Welcome to Micro ...|          32|       pos|       pos|Emotional|\n",
            "|[FN] Path of Chan...|             Aftel43|    2|18hjv4t|https://www.reddi...|2023-12-13 15:53:18|After two weeks o...|           1|       pos|       neg|Emotional|\n",
            "|Daddy's Little Gi...|          scott24h16|    2| 1ws1zq|https://www.reddi...|2014-02-02 03:24:01|This story is ent...|           0|       neg|       pos|Emotional|\n",
            "|[RO] My short sto...|      MoneyTakerBaby|    6|11kzcuc|https://www.reddi...|2023-03-07 13:28:26|Hello reddit! I j...|           3|       pos|       pos|Emotional|\n",
            "|[SerSun] Serial S...|             OldBayJ|   12|151e7jm|https://www.reddi...|2023-07-16 18:53:47|Welcome to Serial...|          89|       pos|       pos|Emotional|\n",
            "|[SF] The Oddities...|     TrueGodOfHollow|    1|14qehmb|https://www.reddi...|2023-07-04 12:55:54|In the deep of th...|           1|       pos|       pos|Emotional|\n",
            "|[MS] Who's really...|      Inevitable_Jex|    6| r463ol|https://www.reddi...|2021-11-28 14:58:38|This is how it st...|           1|   neutral|       neg|Emotional|\n",
            "|[UR] Living Color...|Satellite_To_The_Sun|    2| 7h29g1|https://www.reddi...|2017-12-02 11:55:25|John had never ta...|           2|       neg|       pos|Emotional|\n",
            "|[MF] Too Much, No...|    fre_sh_a_v0ca_d0|    1|1b0z75g|https://www.reddi...|2024-02-27 01:30:05|\\r  \\nChapter 1 T...|           2|       pos|       pos|Emotional|\n",
            "|[MF] In The Midst...|      MachineHoliday|    0|1azz776|https://www.reddi...|2024-02-25 21:16:29|As Stephen walked...|           2|       neg|       pos|Emotional|\n",
            "|Impervious - a sh...|         Mattonicide|    1| 17fbr2|https://www.reddi...|2013-01-28 12:25:07|Liquid bubbles fa...|           0|       pos|       pos|Emotional|\n",
            "|Emotions Overridi...|  makemusicnotwar420|    3| 1dvewh|https://www.reddi...|2013-05-07 17:13:52|This, this a stor...|           0|       pos|       neg|Emotional|\n",
            "|[MF] The Peak of ...|            gammarik|    3| nwvq2z|https://www.reddi...|2021-06-10 19:08:57|The mother climbs...|           4|       pos|       pos|Emotional|\n",
            "|[NF] A Life of Ch...|          Phyla_Arau|    1|13hunne|https://www.reddi...|2023-05-15 02:16:38|Days pass. Nothin...|           2|       pos|       neg|Emotional|\n",
            "|Flash-Back Short ...|      Jeremiah123098|    1| 1nuypr|https://www.reddi...|2013-10-06 19:47:25|On April 18th, a ...|           0|       neg|       pos|Emotional|\n",
            "|    [RF] the pointer|          Boris35635|    2|15yqt5q|https://www.reddi...|2023-08-23 02:36:47| As kids we are t...|           2|       neg|       neg|Emotional|\n",
            "|[OT] Micro Monday...|             OldBayJ|    8|17zxi9t|https://www.reddi...|2023-11-20 20:04:00|Welcome to Micro ...|          34|       pos|       pos|Emotional|\n",
            "|[MF] Studies in E...|          ElkeKerman|    2| 3clpea|https://www.reddi...|2015-07-08 21:52:50|A thin gasping ca...|           0|       neg|       pos|Emotional|\n",
            "+--------------------+--------------------+-----+-------+--------------------+-------------------+--------------------+------------+----------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "combine_final_df.coalesce(1).write.option(\"header\", \"true\").csv(\"final_sentiment_analysis_results.csv\", mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "vMT_w8SuVqt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bmXsx9_6XuM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_test = pd.read_csv(\"/content/part-00000-c681fe9e-6d8b-40e0-ad60-c6bcfd825425-c000.csv\",error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnmAgxmuXv48",
        "outputId": "ce8b3e93-32c5-42d6-bf92-5d327b905bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-1c35df0ac7c5>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  pandas_test = pd.read_csv(\"/content/part-00000-c681fe9e-6d8b-40e0-ad60-c6bcfd825425-c000.csv\",error_bad_lines=False)\n",
            "Skipping line 315: expected 11 fields, saw 12\n",
            "Skipping line 349: expected 11 fields, saw 13\n",
            "Skipping line 365: expected 11 fields, saw 12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_test.to_csv(\"Sentiment_Analysis_Report.csv\")"
      ],
      "metadata": {
        "id": "BaOlSvPxiGS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuLVShEBiIm1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}